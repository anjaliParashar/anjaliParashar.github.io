---
title: "On the stability of gradient descent
with second order dynamics for time-varying cost functions"
collection: publications
category: manuscripts
permalink: /publication/TMLR_2025
excerpt: 'Provable stability for second-order gradient based optimization for time-varying cost functions'
venue: 'Transactions on Machine Learning Research'
date: 2025-03-12
paperurl: 'https://openreview.net/pdf?id=HlzjI2fn2T'
citation: 'T.E. Gibson, S. Acharya, A. Parashar, J.E. Gaudio, A.M. Annaswamy (2025). &quot;On the stability of gradient descent
with second order dynamics for time-varying cost functions; <i>Transactions on Machine Learning Research</i>.'
---

This work explores the usage of end-to-end differentiable simulators for failure discovery and repair, combined with a gradient-based sampling approach (Metropolis-Adjusted Langevin Algorithm aka MALA) for falsification and repair of data-driven policies in autonomous systems. We provide  end-to-end differentiable simulators written in JAX for manipulation and self-driving tasks, and validate our sampling based algorithms for failure discovery and repair, with higher failure discovery and repair rate compared to baselines such as Learning to Collide (L2C), REINFORCE, vanilla gradient-based optimization and black-box sampling.
